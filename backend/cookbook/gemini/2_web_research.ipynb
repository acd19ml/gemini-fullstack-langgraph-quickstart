{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import add_messages\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "import operator\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    search_query: Annotated[list, operator.add]\n",
    "    web_research_result: Annotated[list, operator.add]\n",
    "    sources_gathered: Annotated[list, operator.add]\n",
    "    initial_search_query_count: int\n",
    "    max_research_loops: int\n",
    "    research_loop_count: int\n",
    "    reasoning_model: str\n",
    "\n",
    "class WebSearchState(TypedDict):\n",
    "    search_query: str\n",
    "    id: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Any, Optional\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "class Configuration(BaseModel):\n",
    "    \"\"\"The configuration for the agent.\"\"\"\n",
    "\n",
    "    query_generator_model: str = Field(\n",
    "        default=\"gemini-2.0-flash\",\n",
    "        metadata={\n",
    "            \"description\": \"The name of the language model to use for the agent's query generation.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    max_research_loops: int = Field(\n",
    "        default=2,\n",
    "        metadata={\"description\": \"The maximum number of research loops to perform.\"},\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def from_runnable_config(\n",
    "        cls, config: Optional[RunnableConfig] = None\n",
    "    ) -> \"Configuration\":\n",
    "        \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"\n",
    "        configurable = (\n",
    "            config[\"configurable\"] if config and \"configurable\" in config else {}\n",
    "        )\n",
    "\n",
    "        # Get raw values from environment or config\n",
    "        raw_values: dict[str, Any] = {\n",
    "            name: os.environ.get(name.upper(), configurable.get(name))\n",
    "            for name in cls.model_fields.keys()\n",
    "        }\n",
    "\n",
    "        # Filter out None values\n",
    "        values = {k: v for k, v in raw_values.items() if v is not None}\n",
    "\n",
    "        return cls(**values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Get current date in a readable format\n",
    "def get_current_date():\n",
    "    return datetime.now().strftime(\"%B %d, %Y\")\n",
    "web_searcher_instructions = \"\"\"Conduct targeted Google Searches to gather the most recent, credible information on \"{research_topic}\" and synthesize it into a verifiable text artifact.\n",
    "\n",
    "Instructions:\n",
    "- Query should ensure that the most current information is gathered. The current date is {current_date}.\n",
    "- Conduct multiple, diverse searches to gather comprehensive information.\n",
    "- Consolidate key findings while meticulously tracking the source(s) for each specific piece of information.\n",
    "- The output should be a well-written summary or report based on your search findings. \n",
    "- Only include the information found in the search results, don't make up any information.\n",
    "\n",
    "Research Topic:\n",
    "{research_topic}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "from google.genai import Client\n",
    "# Used for Google Search API\n",
    "genai_client = Client(api_key=os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "from typing import Any, Dict, List\n",
    "def resolve_urls(urls_to_resolve: List[Any], id: int) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Create a map of the vertex ai search urls (very long) to a short url with a unique id for each url.\n",
    "    Ensures each original URL gets a consistent shortened form while maintaining uniqueness.\n",
    "    \"\"\"\n",
    "    prefix = f\"https://vertexaisearch.cloud.google.com/id/\"\n",
    "    urls = [site.web.uri for site in urls_to_resolve]\n",
    "\n",
    "    # Create a dictionary that maps each unique URL to its first occurrence index\n",
    "    resolved_map = {}\n",
    "    for idx, url in enumerate(urls):\n",
    "        if url not in resolved_map:\n",
    "            resolved_map[url] = f\"{prefix}{id}-{idx}\"\n",
    "\n",
    "    return resolved_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def get_citations(response, resolved_urls_map):\n",
    "    \"\"\"\n",
    "    Extracts and formats citation information from a Gemini model's response.\n",
    "\n",
    "    This function processes the grounding metadata provided in the response to\n",
    "    construct a list of citation objects. Each citation object includes the\n",
    "    start and end indices of the text segment it refers to, and a string\n",
    "    containing formatted markdown links to the supporting web chunks.\n",
    "\n",
    "    Args:\n",
    "        response: The response object from the Gemini model, expected to have\n",
    "                  a structure including `candidates[0].grounding_metadata`.\n",
    "                  It also relies on a `resolved_map` being available in its\n",
    "                  scope to map chunk URIs to resolved URLs.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary represents a citation\n",
    "              and has the following keys:\n",
    "              - \"start_index\" (int): The starting character index of the cited\n",
    "                                     segment in the original text. Defaults to 0\n",
    "                                     if not specified.\n",
    "              - \"end_index\" (int): The character index immediately after the\n",
    "                                   end of the cited segment (exclusive).\n",
    "              - \"segments\" (list[str]): A list of individual markdown-formatted\n",
    "                                        links for each grounding chunk.\n",
    "              - \"segment_string\" (str): A concatenated string of all markdown-\n",
    "                                        formatted links for the citation.\n",
    "              Returns an empty list if no valid candidates or grounding supports\n",
    "              are found, or if essential data is missing.\n",
    "    \"\"\"\n",
    "    citations = []\n",
    "\n",
    "    # Ensure response and necessary nested structures are present\n",
    "    if not response or not response.candidates:\n",
    "        return citations\n",
    "\n",
    "    candidate = response.candidates[0]\n",
    "    if (\n",
    "        not hasattr(candidate, \"grounding_metadata\")\n",
    "        or not candidate.grounding_metadata\n",
    "        or not hasattr(candidate.grounding_metadata, \"grounding_supports\")\n",
    "    ):\n",
    "        return citations\n",
    "\n",
    "    for support in candidate.grounding_metadata.grounding_supports:\n",
    "        citation = {}\n",
    "\n",
    "        # Ensure segment information is present\n",
    "        if not hasattr(support, \"segment\") or support.segment is None:\n",
    "            continue  # Skip this support if segment info is missing\n",
    "\n",
    "        start_index = (\n",
    "            support.segment.start_index\n",
    "            if support.segment.start_index is not None\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        # Ensure end_index is present to form a valid segment\n",
    "        if support.segment.end_index is None:\n",
    "            continue  # Skip if end_index is missing, as it's crucial\n",
    "\n",
    "        # Add 1 to end_index to make it an exclusive end for slicing/range purposes\n",
    "        # (assuming the API provides an inclusive end_index)\n",
    "        citation[\"start_index\"] = start_index\n",
    "        citation[\"end_index\"] = support.segment.end_index\n",
    "\n",
    "        citation[\"segments\"] = []\n",
    "        if (\n",
    "            hasattr(support, \"grounding_chunk_indices\")\n",
    "            and support.grounding_chunk_indices\n",
    "        ):\n",
    "            for ind in support.grounding_chunk_indices:\n",
    "                try:\n",
    "                    chunk = candidate.grounding_metadata.grounding_chunks[ind]\n",
    "                    resolved_url = resolved_urls_map.get(chunk.web.uri, None)\n",
    "                    citation[\"segments\"].append(\n",
    "                        {\n",
    "                            \"label\": chunk.web.title.split(\".\")[:-1][0],\n",
    "                            \"short_url\": resolved_url,\n",
    "                            \"value\": chunk.web.uri,\n",
    "                        }\n",
    "                    )\n",
    "                except (IndexError, AttributeError, NameError):\n",
    "                    # Handle cases where chunk, web, uri, or resolved_map might be problematic\n",
    "                    # For simplicity, we'll just skip adding this particular segment link\n",
    "                    # In a production system, you might want to log this.\n",
    "                    pass\n",
    "        citations.append(citation)\n",
    "    return citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def insert_citation_markers(text, citations_list):\n",
    "    \"\"\"\n",
    "    Inserts citation markers into a text string based on start and end indices.\n",
    "\n",
    "    Args:\n",
    "        text (str): The original text string.\n",
    "        citations_list (list): A list of dictionaries, where each dictionary\n",
    "                               contains 'start_index', 'end_index', and\n",
    "                               'segment_string' (the marker to insert).\n",
    "                               Indices are assumed to be for the original text.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with citation markers inserted.\n",
    "    \"\"\"\n",
    "    # Sort citations by end_index in descending order.\n",
    "    # If end_index is the same, secondary sort by start_index descending.\n",
    "    # This ensures that insertions at the end of the string don't affect\n",
    "    # the indices of earlier parts of the string that still need to be processed.\n",
    "    sorted_citations = sorted(\n",
    "        citations_list, key=lambda c: (c[\"end_index\"], c[\"start_index\"]), reverse=True\n",
    "    )\n",
    "\n",
    "    modified_text = text\n",
    "    for citation_info in sorted_citations:\n",
    "        # These indices refer to positions in the *original* text,\n",
    "        # but since we iterate from the end, they remain valid for insertion\n",
    "        # relative to the parts of the string already processed.\n",
    "        end_idx = citation_info[\"end_index\"]\n",
    "        marker_to_insert = \"\"\n",
    "        for segment in citation_info[\"segments\"]:\n",
    "            marker_to_insert += f\" [{segment['label']}]({segment['short_url']})\"\n",
    "        # Insert the citation marker at the original end_idx position\n",
    "        modified_text = (\n",
    "            modified_text[:end_idx] + marker_to_insert + modified_text[end_idx:]\n",
    "        )\n",
    "\n",
    "    return modified_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_research(state: WebSearchState, config: RunnableConfig) -> OverallState:\n",
    "    \"\"\"LangGraph node that performs web research using the native Google Search API tool.\n",
    "\n",
    "    Executes a web search using the native Google Search API tool in combination with Gemini 2.0 Flash.\n",
    "\n",
    "    Args:\n",
    "        state: Current graph state containing the search query and research loop count\n",
    "        config: Configuration for the runnable, including search API settings\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with state update, including sources_gathered, research_loop_count, and web_research_results\n",
    "    \"\"\"\n",
    "    # Configure\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    formatted_prompt = web_searcher_instructions.format(\n",
    "        current_date=get_current_date(),\n",
    "        research_topic=state[\"search_query\"],\n",
    "    )\n",
    "\n",
    "    # Uses the google genai client as the langchain client doesn't return grounding metadata\n",
    "    response = genai_client.models.generate_content(\n",
    "        model=configurable.query_generator_model,\n",
    "        contents=formatted_prompt,\n",
    "        config={\n",
    "            \"tools\": [{\"google_search\": {}}],\n",
    "            \"temperature\": 0,\n",
    "        },\n",
    "    )\n",
    "    # resolve the urls to short urls for saving tokens and time\n",
    "    resolved_urls = resolve_urls(\n",
    "        response.candidates[0].grounding_metadata.grounding_chunks, state[\"id\"]\n",
    "    )\n",
    "    # Gets the citations and adds them to the generated text\n",
    "    citations = get_citations(response, resolved_urls)\n",
    "    modified_text = insert_citation_markers(response.text, citations)\n",
    "    sources_gathered = [item for citation in citations for item in citation[\"segments\"]]\n",
    "\n",
    "    return {\n",
    "        \"sources_gathered\": sources_gathered,\n",
    "        \"search_query\": [state[\"search_query\"]],\n",
    "        \"web_research_result\": [modified_text],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sources_gathered': [{'label': 'iot-analytics', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGYbmqlH1GAIEzLkjsOCbgF7vEsONIdiI8tXfyKpSB8zejqCpYHTGEUdsDQ-mM4y0cHGrKOOMb2u7VJMHh62VQePcfpil9ZEi8RQQgFlzsFGu6QXO2Qjj6WvRKvFFxsFtQThohXJ4PH4ztp-tA96AyqUlC5dIs='}, {'label': 'iot-analytics', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGYbmqlH1GAIEzLkjsOCbgF7vEsONIdiI8tXfyKpSB8zejqCpYHTGEUdsDQ-mM4y0cHGrKOOMb2u7VJMHh62VQePcfpil9ZEi8RQQgFlzsFGu6QXO2Qjj6WvRKvFFxsFtQThohXJ4PH4ztp-tA96AyqUlC5dIs='}, {'label': 'iot-analytics', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGYbmqlH1GAIEzLkjsOCbgF7vEsONIdiI8tXfyKpSB8zejqCpYHTGEUdsDQ-mM4y0cHGrKOOMb2u7VJMHh62VQePcfpil9ZEi8RQQgFlzsFGu6QXO2Qjj6WvRKvFFxsFtQThohXJ4PH4ztp-tA96AyqUlC5dIs='}, {'label': 'iot-analytics', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGYbmqlH1GAIEzLkjsOCbgF7vEsONIdiI8tXfyKpSB8zejqCpYHTGEUdsDQ-mM4y0cHGrKOOMb2u7VJMHh62VQePcfpil9ZEi8RQQgFlzsFGu6QXO2Qjj6WvRKvFFxsFtQThohXJ4PH4ztp-tA96AyqUlC5dIs='}, {'label': 'iot-analytics', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGYbmqlH1GAIEzLkjsOCbgF7vEsONIdiI8tXfyKpSB8zejqCpYHTGEUdsDQ-mM4y0cHGrKOOMb2u7VJMHh62VQePcfpil9ZEi8RQQgFlzsFGu6QXO2Qjj6WvRKvFFxsFtQThohXJ4PH4ztp-tA96AyqUlC5dIs='}, {'label': 'stateof', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHwIa8tnZkIVHBd8KCDK7_USxFnkzpu1hLmbUjmK9g6Kw2UHtPPkDQ-sMgU-6qlY7YtxDCnQ87aRB2z3rQE64sVH5bAhxdXByXVB7cE6NTL9HMT'}, {'label': 'iot-analytics', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGYbmqlH1GAIEzLkjsOCbgF7vEsONIdiI8tXfyKpSB8zejqCpYHTGEUdsDQ-mM4y0cHGrKOOMb2u7VJMHh62VQePcfpil9ZEi8RQQgFlzsFGu6QXO2Qjj6WvRKvFFxsFtQThohXJ4PH4ztp-tA96AyqUlC5dIs='}, {'label': 'inc', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEUIR4joYoCiaZp7ZQljhknE6rfYHRGBkyYiYxp_H4ANslCCvruxakvkGkqqbzwUuVpj_EbSjAYoMlSPk_DVp5TrEK7jgPXF7VUUv24751LeXOCkEvlT-oDCO7B2YbEVQp-L0PIWJwxCtytxTcibibR61WWsjICz8SH5DXh8mnH8RReE7muWEMLoU5RhmPQtdugKuz5cReET-qNKZtDUQ=='}, {'label': 'stateof', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-1', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHwIa8tnZkIVHBd8KCDK7_USxFnkzpu1hLmbUjmK9g6Kw2UHtPPkDQ-sMgU-6qlY7YtxDCnQ87aRB2z3rQE64sVH5bAhxdXByXVB7cE6NTL9HMT'}, {'label': 'blog', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-3', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXE815hmNrj9ueaWWfYOT1R0rVrqGPpd5gDHOUCU8AhTXV_D_Pp75dD2Me6ODXzOwIFhEwDAqDUp-Mqy02NqfxXqAsnbk3yJ3dLax8Vg91IpwG9lx0EQGINJiCo1ICB2F_sC0ScguMYyG7dNefG7Spy0LoLNUPrYo5W3tr3dpZSciluWMpGz-RrX'}, {'label': 'debabratapruseth', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGxtbluVUeQlQVK_ta_A1t0B2Tcf8Sxr8dBUN_5xFFODtJvdd_opap1AiT7aXNXPHuD12a6zh9a-u8pDp_6Hl3248_do9T31StMZ-Kubi7ZERcpUw7EEIh06Z7sRi2ROL_n-oLvCNcYrCqBwYlkGZDqYNQ9-PdxJhbd6Ho2BvNalwJLEHq6r4VvUIFFNKmOCeFNv8MPm2_Rf1XwZappWNGNMpvJ'}, {'label': 'debabratapruseth', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-4', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGxtbluVUeQlQVK_ta_A1t0B2Tcf8Sxr8dBUN_5xFFODtJvdd_opap1AiT7aXNXPHuD12a6zh9a-u8pDp_6Hl3248_do9T31StMZ-Kubi7ZERcpUw7EEIh06Z7sRi2ROL_n-oLvCNcYrCqBwYlkGZDqYNQ9-PdxJhbd6Ho2BvNalwJLEHq6r4VvUIFFNKmOCeFNv8MPm2_Rf1XwZappWNGNMpvJ'}, {'label': 'blog', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-5', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF9UarEYbT0iRzY2pAsEc5o2UWzq1ZuNrIlicExC_gZFcyjj9MMS2fd2GFGpYZc6sXVg6HVrCbzpKQR2z6VDruemWiT0WBQ0s4tAITAKZYJysmsID6Mcj42X8gohshQTBzCQFNPR3UWvdY7ib-NeMEwl0K1N4mRq_TNqGLZuBNNArOM7dfSxvHITw=='}, {'label': 'rdworldonline', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-6', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFLImYKGjbmZklyTa-odQnzahDig4PgqKE0Sad0UryAu9tXDLgA10GwZCuvUuNK5OD_B2lR0d8q1TM9Ajce0FbCm3wmyyg2pIAJ7B9EiY_k928wboxa8CtCsj-gC9CNYQF5EM84vEBV7hnQhCytYNUrpJmG8l1Oi1_EGA=='}, {'label': 'youtube', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-7', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH0o-j5jOYqkygi8U3lNNMr9vImPFMfQoYV6a1ZiG9qU5RLmZtvWgWWu4mZOjwyif5AYScWx9JMeElPsKeFJgq2pQnwtQGozoEQ-q9ccM2HxGSjv4qYJUd2g4xODYyCNUAjETKddtQ='}, {'label': 'iot-analytics', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGYbmqlH1GAIEzLkjsOCbgF7vEsONIdiI8tXfyKpSB8zejqCpYHTGEUdsDQ-mM4y0cHGrKOOMb2u7VJMHh62VQePcfpil9ZEi8RQQgFlzsFGu6QXO2Qjj6WvRKvFFxsFtQThohXJ4PH4ztp-tA96AyqUlC5dIs='}, {'label': 'inc', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-2', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEUIR4joYoCiaZp7ZQljhknE6rfYHRGBkyYiYxp_H4ANslCCvruxakvkGkqqbzwUuVpj_EbSjAYoMlSPk_DVp5TrEK7jgPXF7VUUv24751LeXOCkEvlT-oDCO7B2YbEVQp-L0PIWJwxCtytxTcibibR61WWsjICz8SH5DXh8mnH8RReE7muWEMLoU5RhmPQtdugKuz5cReET-qNKZtDUQ=='}, {'label': 'iot-analytics', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-0', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGYbmqlH1GAIEzLkjsOCbgF7vEsONIdiI8tXfyKpSB8zejqCpYHTGEUdsDQ-mM4y0cHGrKOOMb2u7VJMHh62VQePcfpil9ZEi8RQQgFlzsFGu6QXO2Qjj6WvRKvFFxsFtQThohXJ4PH4ztp-tA96AyqUlC5dIs='}, {'label': 'blog', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-8', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGGiOFfwg1XKp9aADwVi4EKUeXbJnNY3AzwVwLeszCwT-jBE9zodxbN1O1aCbfHDiX9ylh_RyKsY5LziFe5J-WsSt8VoPluEGEvOkfcKEbsC1n0cci9rj-7LD1z22qbxWQCCPngfswwRBG5gPqIhFPBBBA9qp2NhNAgWGihLKQea-POg0hG'}, {'label': 'forbes', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-9', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXH4vtutirj6OF4cyqOiIzLwxsRHnDQ6KvADZJP9s3J6TukJte3n4aLnaPJe1TjW7WT4aUGZg1HCO1AhfazDEY5BKfBH7T4aZnDKbIHVS5Ar6qSngsgZhg1XZ1NxrW6sGHo2BlRkqT0bfmPAFgg3K9yKAbEK-d-kCHA21hWMfkzld-SCTNUPJyxCANexrQU4SizW7nu-s3rb-BMQoY9tBQdJyoM='}, {'label': 'kenja', 'short_url': 'https://vertexaisearch.cloud.google.com/id/0-10', 'value': 'https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHL8Gav1qOWKRJ1iQb7qh8W0qZZmhcjrU_xODGd-GjoGhIo2B8NjSyGv9--LPE5vT2e71T9MMMVtQGEC5ksvgBBAM0tBS3Pi0Cv0AVPSTsunJ13WbXGA1VYd9O3yJC-791Z0AzyE36j4oWe8nmCtpGvuSSI6Q=='}], 'search_query': ['major AI research breakthroughs 2024'], 'web_research_result': ['Okay, I will conduct Google Searches to gather information on major AI research breakthroughs in 2024 and synthesize it into a verifiable text artifact.\\n\\nBased on the search results, here\\'s a summary of major AI research breakthroughs in 2024:\\n\\n**General Trends and Market Developments:**\\n\\n*   **AI Boom and Market Growth:** 2024 saw a significant AI boom, driving record valuations and market growth. [iot-analytics](https://vertexaisearch.cloud.google.com/id/0-0) Companies like NVIDIA, Broadcom, and Microsoft experienced strong revenue growth from AI. [iot-analytics](https://vertexaisearch.cloud.google.com/id/0-0) NVIDIA\\'s revenue from data center GPUs increased by an estimated 142%, pushing its market capitalization to over $3.5 trillion. [iot-analytics](https://vertexaisearch.cloud.google.com/id/0-0) OpenAI and xAI both raised over $6 billion in funding rounds. [iot-analytics](https://vertexaisearch.cloud.google.com/id/0-0) The tech-heavy NASDAQ surpassed 20,000 points for the first time due to the AI wave (IoT Analytics [1]). [iot-analytics](https://vertexaisearch.cloud.google.com/id/0-0)\\n*   **Increased AI Adoption:** The use of generative AI increased significantly, with 71% of organizations regularly using it in at least one business function, up from 33% in 2023 (McKinsey [3]).\\n*   **Focus on AI Safety and Regulation:** A global debate raged about AI regulation, with the EU taking an early lead with its Artificial Intelligence Act (Inc. Magazine [4], Forbes [6]). Safety became a key dimension in AI research and development (State of AI Report [7]). [stateof](https://vertexaisearch.cloud.google.com/id/0-1)\\n\\n**Key AI Advancements and Breakthroughs:**\\n\\n*   **Large Language Models (LLMs):**\\n    *   **Meta\\'s LLaMa 3.1:** Meta introduced its updated LLaMA 3.1, which outperformed closed models like ChatGPT and Claude in benchmark tests (IoT Analytics [1]). [iot-analytics](https://vertexaisearch.cloud.google.com/id/0-0)\\n    *   **OpenAI\\'s GPT-4o:** OpenAI released the GPT-4o model, featuring advanced audio chat capabilities with human-like voices (Inc. Magazine [4]). [inc](https://vertexaisearch.cloud.google.com/id/0-2)\\n    *   **Planning and Reasoning in LLMs:** Research prioritized planning and reasoning in LLMs, exploring combinations with reinforcement learning and evolutionary algorithms (State of AI Report [7]). [stateof](https://vertexaisearch.cloud.google.com/id/0-1)\\n*   **Multimodal AI:**\\n    *   **Gemini 2.0:** Google released Gemini 2.0, designed for the \"agentic era,\" and integrated it into various products (Google Blog [2]). [blog](https://vertexaisearch.cloud.google.com/id/0-3) Google\\'s DeepMind also introduced Gemini 2.0 Flash, capable of interpreting and generating text, images, and audio (2024: The Transformative Year in AI [12]). [debabratapruseth](https://vertexaisearch.cloud.google.com/id/0-4)\\n*   **AI in Science and Research:**\\n    *   **AlphaFold:** AI, particularly DeepMind\\'s AlphaFold, contributed to groundbreaking protein structure predictions, earning its creators the Nobel Prize in Chemistry (Forbes [6], 2024: The Transformative Year in AI [12]). [debabratapruseth](https://vertexaisearch.cloud.google.com/id/0-4)\\n    *   **AlphaGeometry:** Google DeepMind announced AlphaGeometry, an AI system that solved complex geometry problems at a level approaching a human Olympiad gold-medalist (Google Blog [5]). [blog](https://vertexaisearch.cloud.google.com/id/0-5)\\n    *   **Disease Prediction:** AI learned to better predict disease, analyzing clinical biomarkers and plasma proteins to achieve high predictability for numerous diseases (24 R&D breakthroughs that shaped 2024 [13]).\\n*   **AI in Robotics:**\\n    *   **Advancements in Robotics Learning:** Robots made significant strides in learning complex tasks through imitation and reinforcement learning (Top 10 AI Breakthroughs of 2024 - YouTube [8]).\\n    *   **Humanoid Robots:** Figure Inc. unveiled Figure 02, a second-generation humanoid robot designed for various tasks and featuring speech interaction powered by custom AI models co-developed with OpenAI (24 R&D breakthroughs that shaped 2024 [13]). [rdworldonline](https://vertexaisearch.cloud.google.com/id/0-6)\\n*   **Other Notable Advancements:**\\n    *   **AI in Weather Forecasting:** Google DeepMind\\'s GenCast significantly advanced weather prediction, accurately forecasting extreme weather events (Top 10 AI Breakthroughs of 2024 - YouTube [8]).\\n    *   **AI in Cancer Diagnosis:** AI models like Harvard\\'s \"Chief\" made waves by diagnosing rare cancers with unprecedented accuracy (Top 10 AI Breakthroughs of 2024 - YouTube [8]).\\n    *   **AI for Scientific Discovery:** AI is accelerating our understanding of the universe, with researchers making advances in brain mapping and chemistry (Top 10 AI Breakthroughs of 2024 - YouTube [8]). [youtube](https://vertexaisearch.cloud.google.com/id/0-7)\\n    *   **Graphene Semiconductor:** Researchers at the Georgia Institute of Technology announced the first functional graphene semiconductor (24 R&D breakthroughs that shaped 2024 [13]).\\n\\n**Challenges and Concerns:**\\n\\n*   **Inability to Improve LLM Performance:** Major LLM advancement projects faced challenges in meeting their targets (IoT Analytics [1]). [iot-analytics](https://vertexaisearch.cloud.google.com/id/0-0)\\n*   **AI Safety Concerns:** The departure of key executives from OpenAI\\'s safety team raised concerns about the rapid development and deployment of potentially unsafe AIs (Inc. Magazine [4]). [inc](https://vertexaisearch.cloud.google.com/id/0-2)\\n*   **Job Displacement:** Surveys indicated that companies replaced workers with AI in 2024, with more expecting to do so in 2025 (IoT Analytics [1]). [iot-analytics](https://vertexaisearch.cloud.google.com/id/0-0)\\n\\nThis summary is based on information available up to June 11, 2025. The field of AI is rapidly evolving, and new breakthroughs are continuously being developed. [blog](https://vertexaisearch.cloud.google.com/id/0-8) [forbes](https://vertexaisearch.cloud.google.com/id/0-9) [kenja](https://vertexaisearch.cloud.google.com/id/0-10)\\n']}\n"
     ]
    }
   ],
   "source": [
    "# 确保已导入所有依赖和定义\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# 构造 state\n",
    "state = {\n",
    "    \"search_query\": \"major AI research breakthroughs 2024\",\n",
    "    \"id\": \"0\"\n",
    "}\n",
    "\n",
    "# 构造 config\n",
    "config = RunnableConfig({})\n",
    "\n",
    "# 调用 web_research\n",
    "result = web_research(state, config)\n",
    "\n",
    "# 打印结果\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv-gemini)",
   "language": "python",
   "name": "venv-gemini"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
